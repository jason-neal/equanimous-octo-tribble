{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joblib for Daniel:\n",
    "\n",
    "Trying to implement parallelism into Daniels problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Some Tests with random values\n",
    "I don't know if these quite match your data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def griddata(gridpoints, tlayer, teff_logg_feh, method='linear', rescale=True):\n",
    "    \"\"\" Do what ever it does\"\"\"\n",
    "    # put a short wait.\n",
    "    time.sleep(0.5)\n",
    "    return np.sum(tlayer) * teff_logg_feh[0] + teff_logg_feh[1] + teff_logg_feh[2]   # thing to test inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inside_loop(newatm, models, layer, column, gridpoints, teff_logg_feh):\n",
    "    tlayer = np.zeros( len(models))\n",
    "    for inx, model in enumerate(models):\n",
    "        tlayer[indx] = model[layer, column]\n",
    "    #print(\" for layer = {0}, column = {1}\".format(layer, column))\n",
    "    print(\"[Worker %d] Layer %d and Column %d is about to griddata\" % (os.getpid(), layer, column))\n",
    "    newatm[layer,column] = griddata(gridpoints, tlayer, teff_logg_feh, method='linear', rescale=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = range(3)\n",
    "columns = range(2)\n",
    "gridpoints = 5\n",
    "teff = 1000\n",
    "logg = 1\n",
    "feh = -0.01\n",
    "model1 = np.array([[1,2],[3,4],[5,6]])\n",
    "model2 = np.array([[7,8],[9,10],[11,12]])\n",
    "models = [model1, model2, model1*2, model2*2] # random models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Worker 7170] Layer 0 and Column 0 is about to griddata\n",
      "[Worker 7170] Layer 0 and Column 1 is about to griddata\n",
      "[Worker 7170] Layer 1 and Column 0 is about to griddata\n",
      "[Worker 7170] Layer 1 and Column 1 is about to griddata\n",
      "[Worker 7170] Layer 2 and Column 0 is about to griddata\n",
      "[Worker 7170] Layer 2 and Column 1 is about to griddata\n",
      "[[ 14000.99  16000.99]\n",
      " [ 18000.99  20000.99]\n",
      " [ 22000.99  24000.99]]\n"
     ]
    }
   ],
   "source": [
    "#%%timeit \n",
    "newatm = np.zeros([len(layers), len(columns)])\n",
    "generator = (inside_loop(newatm, models, layer, column, gridpoints, (teff, logg, feh)) for  layer in layers for column in columns)\n",
    "\n",
    "for i in generator:\n",
    "    #print(newatm)\n",
    "    pass\n",
    "print(newatm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "# Turning parallel\n",
    "newatm = np.zeros([len(layers), len(columns)])\n",
    "print(\"newatm before parallel\", newatm)\n",
    "Parallel(n_jobs=-1, verbose=1) (delayed(inside_loop)(newatm, models, layer, column, gridpoints, (teff, logg, feh)) for layer in layers for column in columns)\n",
    "\n",
    "time.sleep(0.5)\n",
    "print(\"newatm after parallel\", newatm)\n",
    "\n",
    "# This runs in parallel but it does not return any data yet.\n",
    "\n",
    "#Need to memmap the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel over both loops with memapping\n",
    "Look here to implement the memmap to your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('newatm before parallel', memmap([[0, 0],\n",
      "       [0, 0],\n",
      "       [0, 0]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of   6 | elapsed:    0.5s remaining:   -0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   6 | elapsed:    0.5s remaining:   -0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   6 | elapsed:    0.5s remaining:   -0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   6 | elapsed:    1.0s remaining:   -0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   6 | elapsed:    1.0s remaining:   -0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('newatm after parallel', memmap([[1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1]]))\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import load, dump\n",
    "\n",
    "def inside_loop(newatm, models, layer, column, gridpoints, teff_logg_feh):\n",
    "    tlayer = np.zeros( len(models))\n",
    "    for inx, model in enumerate(models):\n",
    "        tlayer[indx] = model[layer, column]\n",
    "    newatm[layer,column] = griddata(gridpoints, tlayer, teff_logg_feh, method='linear', rescale=True)\n",
    "    \n",
    "def griddata(gridpoints, tlayer, teff_logg_feh, method='linear', rescale=True):\n",
    "    \"\"\" Do what ever it does\"\"\"\n",
    "    time.sleep(0.5)\n",
    "    return True   # thing to test inputs\n",
    "\n",
    "folder = tempfile.mkdtemp()\n",
    "newatm_name = os.path.join(folder, 'newatm')\n",
    "try:\n",
    "    # Pre-allocate a writeable shared memory map as a container for the\n",
    "    # results of the parallel computation\n",
    "    newatm = np.memmap(newatm_name, dtype=model.dtype, shape=model.shape, mode='w+')  # need to adjsut the shape\n",
    "\n",
    "    print(\"newatm before parallel\", newatm)\n",
    "    Parallel(n_jobs=-1, verbose=1) (delayed(inside_loop)(newatm, models, layer, column, gridpoints, (teff, logg, feh)) for layer in layers for column in columns)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    print(\"newatm after parallel\", newatm)\n",
    "\n",
    "finally:\n",
    "    # deleting temp files after testing the reuslt in example \n",
    "        try:\n",
    "            shutil.rmtree(folder)\n",
    "        except:\n",
    "            print(\"Failed to delete: \" + folder)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct copy of Joblib memmaping example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import load, dump\n",
    "\n",
    "\n",
    "def sum_row(input, output, i):\n",
    "    \"\"\"Compute the sum of a row in input and store it in output\"\"\"\n",
    "    sum_ = input[i, :].sum()\n",
    "    print(\"[Worker %d] Sum for row %d is %f\" % (os.getpid(), i, sum_))\n",
    "    output[i] = sum_\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rng = np.random.RandomState(42)\n",
    "    folder = tempfile.mkdtemp()\n",
    "    samples_name = os.path.join(folder, 'samples')\n",
    "    sums_name = os.path.join(folder, 'sums')\n",
    "    try:\n",
    "        # Generate some data and an allocate an output buffer\n",
    "        samples = rng.normal(size=(10, int(1e6)))\n",
    "\n",
    "        # Pre-allocate a writeable shared memory map as a container for the\n",
    "        # results of the parallel computation\n",
    "        sums = np.memmap(sums_name, dtype=samples.dtype,\n",
    "                         shape=samples.shape[0], mode='w+')\n",
    "        print(\"samples shape\", samples.shape)\n",
    "        # Dump the input data to disk to free the memory\n",
    "        dump(samples, samples_name)\n",
    "\n",
    "        # Release the reference on the original in memory array and replace it\n",
    "        # by a reference to the memmap array so that the garbage collector can\n",
    "        # release the memory before forking. gc.collect() is internally called\n",
    "        # in Parallel just before forking.\n",
    "        samples = load(samples_name, mmap_mode='r')\n",
    "\n",
    "        # Fork the worker processes to perform computation concurrently\n",
    "        Parallel(n_jobs=4)(delayed(sum_row)(samples, sums, i)\n",
    "                           for i in range(samples.shape[0]))\n",
    "\n",
    "        # Compare the results from the output buffer with the ground truth\n",
    "        print(\"Expected sums computed in the parent process:\")\n",
    "        expected_result = samples.sum(axis=1)\n",
    "        print(expected_result)\n",
    "\n",
    "        print(\"Actual sums computed by the worker processes:\")\n",
    "        print(sums)\n",
    "\n",
    "        assert np.allclose(expected_result, sums)\n",
    "    finally:\n",
    "        try:\n",
    "            shutil.rmtree(folder)\n",
    "        except:\n",
    "            print(\"Failed to delete: \" + folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
